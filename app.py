from flask import Flask, request, jsonify
from flask_cors import CORS
import io
from PIL import Image
import torch
from watermark_anything.data.metrics import msg_predict_inference
import os, re
from torchvision import transforms
from datetime import datetime
import base64
import requests
import numpy as np, random

from notebooks.inference_utils import (
    load_model_from_checkpoint,
    create_random_mask,
    unnormalize_img,
)

# ì •ê·œí™” íŒŒë¼ë¯¸í„° (ImageNet ê¸°ì¤€)
image_mean = torch.tensor([0.485, 0.456, 0.406])
image_std = torch.tensor([0.229, 0.224, 0.225])

# ì›ë³¸ í¬ê¸° ìœ ì§€ + ì •ê·œí™”ë§Œ ì ìš©í•˜ëŠ” transform
default_transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=image_mean, std=image_std),
])

# SEED ê³ ì •
SEED = 42

torch.manual_seed(SEED)
torch.use_deterministic_algorithms(True)
np.random.seed(SEED)
random.seed(SEED)
os.environ['PYTHONHASHSEED'] = str(SEED)

# base64 ë³€í™˜ í•¨ìˆ˜
def pil_to_base64(pil_img, fmt="PNG") -> str:
    buf = io.BytesIO()
    pil_img.save(buf, format=fmt)
    buf.seek(0)
    return base64.b64encode(buf.getvalue()).decode("utf-8")

# ì´ë¯¸ì§€ ì „ì†¡ ì§„í–‰ë¥  í•¨ìˆ˜
spring_ip = os.getenv('SPRING_SERVER_IP')
SPRING_SERVER_URL = f'http://{spring_ip}:8080/progress' 

def send_progress_to_spring(task_id, percent, login_id):
    try:
        payload = {
            'taskId': task_id,
            'progress': percent,
            'loginId': login_id
        }
        headers = {
            'Content-Type': 'application/json'
        }
        print(f"Flaskì—ì„œ Springìœ¼ë¡œ POST ìš”ì²­ ë³´ë‚´ëŠ” ì¤‘: {payload}", flush=True)
        requests.post(SPRING_SERVER_URL, json=payload, headers=headers, timeout=1)
    except Exception as e:
        print(f"[WARN] ì§„í–‰ë¥  ì „ì†¡ ì‹¤íŒ¨: {e}")

class ProgressSender:
    def __init__(self, task_id, login_id):
        self.task_id = task_id
        self.login_id = login_id

    def send(self, percent):
        send_progress_to_spring(self.task_id, percent, self.login_id)

# íŒŒì¼ëª…(í•œê¸€ í¬í•¨)
def safe_filename(filename: str) -> str:
    # í™•ì¥ì ë¶„ë¦¬
    name, ext = os.path.splitext(filename)
    # í•œê¸€, ì˜ë¬¸, ìˆ«ì, ì¼ë¶€ íŠ¹ìˆ˜ë¬¸ìë§Œ í—ˆìš© â†’ ë‚˜ë¨¸ì§€ëŠ” ì œê±°
    name = re.sub(r'[^ê°€-í£a-zA-Z0-9_\- ]', '', name)
    # ê³µë°±ì„ _ ë¡œ ë³€í™˜
    name = name.replace(" ", "_")
    return name + ext

app = Flask(__name__)
CORS(app, origins="*")

# ëª¨ë¸ ì¤€ë¹„ (ì„œë²„ ì‹œì‘ ì‹œ 1íšŒë§Œ)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
ckpt_path = "checkpoints/wam_mit.pth"
json_path = "checkpoints/params.json"
wam = load_model_from_checkpoint(json_path, ckpt_path).to(device).eval()

# =========================================================
# ğŸ’¡ ë””ë²„ê·¸ ì½”ë“œ ì¶”ê°€ ì§€ì : ê°€ì¤‘ì¹˜ ë¡œë“œ ì„±ê³µ ì—¬ë¶€ í™•ì¸
# =========================================================
try:
    # ëª¨ë¸ì˜ ì²« ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ì˜ ê°€ì¤‘ì¹˜ ê°’ì„ ì¶œë ¥í•©ë‹ˆë‹¤. 
    # ëª¨ë¸ êµ¬ì¡°ì— ë§ê²Œ 'encoder.conv1.weight'ë¥¼ ìˆ˜ì •í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    first_layer_weights = wam.state_dict()['encoder.conv1.weight']
    
    print(f"[MODEL DEBUG] WAM Layer Shape: {first_layer_weights.shape}")
    print(f"[MODEL DEBUG] WAM First 5 Weights: {first_layer_weights.flatten()[:5].tolist()}", flush=True)
    
except KeyError:
    print("[MODEL DEBUG] WARNING: Cannot find 'encoder.conv1.weight'. Check layer name.", flush=True)
except Exception as e:
    # ì´ ë¡œê·¸ê°€ ì°íŒë‹¤ë©´, ê°€ì¤‘ì¹˜ ë¡œë“œ ìì²´ê°€ ì‹¤íŒ¨í–ˆì„ ê°€ëŠ¥ì„±ì´ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤.
    print(f"[MODEL DEBUG] CRITICAL ERROR: Failed to read WAM state_dict: {e}", flush=True)

num_threads = torch.get_num_threads()
print(f"í˜„ì¬ PyTorch ê¸°ë³¸ ìŠ¤ë ˆë“œ ìˆ˜: {num_threads}")

cpu_count = os.cpu_count()
print(f"CPU ì½”ì–´ ìˆ˜: {cpu_count}")

@app.route('/', methods=['GET'])
def home():
    return "ì„œë²„ êµ¬ë™ ì™„ë£Œ~"

# ì›Œí„°ë§ˆí¬ ì‚½ì…
@app.route('/watermark-insert', methods=['POST'])
def watermarkInsert():
    task_id = request.form.get('taskId') # taskId ë°›ì•„ì˜¤ê¸°
    login_id = request.form.get('loginId') # loginId ë°›ì•„ì˜¤ê¸°

    send_progress = ProgressSender(task_id, login_id)

    # 1. ì´ë¯¸ì§€ì™€ ë©”ì‹œì§€ ë°›ê¸°
    image_file = request.files.get('image')
    message = request.form.get('message', 'ETNL')
    assert len(message) <= 4, "ë©”ì‹œì§€ëŠ” 4ì ì´í•˜ë§Œ ê°€ëŠ¥"
    if not image_file or not message:
        return jsonify({"error": "image, message ë‘˜ ë‹¤ í•„ìš”í•©ë‹ˆë‹¤."}), 400
    
    # ì‘ì—… ì§„í–‰ ìƒíƒœ ì´ˆê¸°í™”
    send_progress.send(0)

    # 2. ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
    image = Image.open(image_file.stream).convert("RGB")
    img_pt = default_transform(image).unsqueeze(0).to(device)

    # 3. ë©”ì‹œì§€ ì „ì²˜ë¦¬
    wm_bits = ''.join(f"{ord(c):08b}" for c in message)
    wm_bits = wm_bits.ljust(32, '0')[:32]
    wm_msg = torch.tensor([[int(bit) for bit in wm_bits]], dtype=torch.float32).to(device)
    
    # ì§„í–‰ ìƒíƒœ 25%ë¡œ ì—…ë°ì´íŠ¸
    send_progress.send(25)

    # 3. ì›Œí„°ë§ˆí¬ ì‚½ì…
    outputs = wam.embed(img_pt, wm_msg)
    mask = create_random_mask(img_pt, num_masks=1, mask_percentage=0.5)
    img_w = outputs['imgs_w'] * mask + img_pt * (1 - mask)

    # ì§„í–‰ ìƒíƒœ 50%ë¡œ ì—…ë°ì´íŠ¸
    send_progress.send(50)

    # 4. ì´ë¯¸ì§€ í›„ì²˜ë¦¬ 
    out_img = unnormalize_img(img_w).squeeze(0).detach().clamp_(0, 1)  # 1. ì •ê·œí™” í•´ì œ + ê°’ ë²”ìœ„ ì œí•œ (0~1)
    out_img_np = out_img.permute(1, 2, 0).cpu().numpy()                # 2. CPUë¡œ ì´ë™ í›„ numpy ë³€í™˜ (HWC í˜•íƒœ)
    out_img_np = (out_img_np * 255).round().astype('uint8')            # 3. 0~255 ë²”ìœ„ë¡œ ë³€í™˜ (ì†Œìˆ˜ì  ì²˜ë¦¬ ê°œì„ )
    out_img_pil = Image.fromarray(out_img_np)                          # 4. PIL ì´ë¯¸ì§€ ìƒì„±
    
    # ì§„í–‰ ìƒíƒœ 75%ë¡œ ì—…ë°ì´íŠ¸
    send_progress.send(75)

    # íŒŒì¼ëª… ì²˜ë¦¬
    original_name = os.path.splitext(safe_filename(image_file.filename))[0]  # example.jpg â†’ example
    ext = os.path.splitext(safe_filename(image_file.filename))[1]            # í™•ì¥ì (jpg, png ë“±)
    watermarked_name = f"{original_name}_deeptruth_watermark{ext}"           # íŒŒì¼ëª… (í™•ì¥ì í¬í•¨)
    
    # ì´ë¯¸ì§€ ì „ì†¡ ì™„ë£Œ
    send_progress.send(100)

    response = jsonify({
        'image_base64': pil_to_base64(out_img_pil),     # ì‚½ì… ì´ë¯¸ì§€
        'message': message,                             # ì›Œí„°ë§ˆí¬ ë©”ì„¸ì§€
        'filename': watermarked_name,                   # ë‹¤ìš´ë¡œë“œ ì‹œ ì‚¬ìš© ë  íŒŒì¼ ì´ë¦„
        'taskId': task_id
    })
    return response

# ì›Œí„°ë§ˆí¬ íƒì§€
@app.route('/watermark-detection', methods=['POST'])
def watermarkDetection():
    try:
        task_id = request.form.get('taskId') # taskId ë°›ì•„ì˜¤ê¸°
        login_id = request.form.get('loginId') # loginId ë°›ì•„ì˜¤ê¸°

        send_progress = ProgressSender(task_id, login_id)

        # 1. ì´ë¯¸ì§€ ìˆ˜ì‹  ë° ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
        image_file = request.files.get('image')
        message = request.form.get('message', '')               # ì‚½ì… ë‹¹ì‹œ ë©”ì‹œì§€ (dbì—ì„œ ê°€ì ¸ì˜¤ëŠ” ê°’)
        if not image_file or not message:
            return jsonify({"error": "image, message ë‘˜ ë‹¤ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
        # ì‘ì—… ì§„í–‰ ìƒíƒœ ì´ˆê¸°í™”
        send_progress.send(0)

        # 2. ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        image = Image.open(image_file.stream).convert("RGB")
        img_pt = default_transform(image).unsqueeze(0).to(device)

        # ì§„í–‰ ìƒíƒœ 25%ë¡œ ì—…ë°ì´íŠ¸
        send_progress.send(25)

        # 3. ì›Œí„°ë§ˆí¬ íƒì§€ (ëª¨ë¸ ì¶”ë¡ )
        with torch.no_grad():
            detect_outputs = wam.detect(img_pt)
            preds = detect_outputs['preds']      # shape: [B, 1+nbits, H, W]
            mask_preds = preds[:, 0:1, :, :]     # ì˜ˆì¸¡ëœ ë§ˆìŠ¤í¬
            bit_preds = preds[:, 1:, :, :]       # ì˜ˆì¸¡ëœ ë©”ì‹œì§€ ë¹„íŠ¸

        # 4. ì˜ˆì¸¡ëœ ë¹„íŠ¸ë¡œë¶€í„° ë©”ì‹œì§€ ì¶”ì¶œ
        pred_message = msg_predict_inference(bit_preds, mask_preds)
        pred_message_float = pred_message.float()  # float32ë¡œ ë³€í™˜

        # ğŸ“Œ [ACCURACY DEBUG] ì˜ˆì¸¡ ë©”ì‹œì§€ ë¡œê·¸
        print(f"[ACCURACY DEBUG] 4. ì˜ˆì¸¡ ë©”ì‹œì§€ (pred_message) shape: {pred_message.shape}, device: {pred_message.device}")
        print(f"[ACCURACY DEBUG] ì˜ˆì¸¡ ë¹„íŠ¸(ì²« 8ê°œ): {pred_message[0, :8].tolist()}")
        
        # ì§„í–‰ ìƒíƒœ 50%ë¡œ ì—…ë°ì´íŠ¸
        send_progress.send(50)
        
        # 5. ì›ë³¸ ë©”ì‹œì§€ í…ì„œ ë³€í™˜
        wm_bits = ''.join(f"{ord(c):08b}" for c in message.ljust(4, '\x00'))[:32]
        wm_tensor = torch.tensor([int(b) for b in wm_bits], dtype=torch.float32).to(device)

        # ğŸ“Œ [ACCURACY DEBUG] ì›ë³¸ ë©”ì‹œì§€ ë¡œê·¸
        print(f"[ACCURACY DEBUG] 5. ì›ë³¸ ë©”ì‹œì§€: '{message}' -> ë¹„íŠ¸ ë¬¸ìì—´ ê¸¸ì´: {len(wm_bits)}")
        print(f"[ACCURACY DEBUG] ì›ë³¸ ë¹„íŠ¸(wm_tensor) shape: {wm_tensor.shape}, device: {wm_tensor.device}")
        print(f"[ACCURACY DEBUG] ì›ë³¸ ë¹„íŠ¸(ì²« 8ê°œ): {wm_tensor[:8].tolist()}", flush=True)

        # comparison_tensor = (pred_message == wm_tensor.unsqueeze(0)).float()
        comparison_tensor = (pred_message_float == wm_tensor.unsqueeze(0)).float()

        # ğŸ“Œ [ACCURACY DEBUG] ë¹„êµ ë¡œê·¸
        num_correct_bits = comparison_tensor.sum().item()
        print(f"[ACCURACY DEBUG] ì¼ì¹˜í•˜ëŠ” ë¹„íŠ¸ ìˆ˜: {num_correct_bits} / 32", flush=True)

        # 6. ë¹„íŠ¸ ì •í™•ë„ ê³„ì‚°
        # bit_acc = (pred_message == wm_tensor.unsqueeze(0)).float().mean().item()
        bit_acc = (pred_message_float == wm_tensor.unsqueeze(0)).float().mean().item()
        bit_acc_pct = round(bit_acc * 100, 1)

        # ğŸ“Œ [ACCURACY DEBUG] ìµœì¢… ì •í™•ë„ ë¡œê·¸
        print(f"[ACCURACY DEBUG] ìµœì¢… ë¹„íŠ¸ ì •í™•ë„ (bit_acc): {bit_acc_pct}%", flush=True)

        # ì§„í–‰ ìƒíƒœ 75%ë¡œ ì—…ë°ì´íŠ¸
        send_progress.send(75)

        # 10. ì‘ë‹µ
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        original_name = os.path.splitext(safe_filename(image_file.filename))[0]  # example.jpg â†’ example
        ext = os.path.splitext(safe_filename(image_file.filename))[1]  
        base_name = f"{original_name}{ext}"

        # ì´ë¯¸ì§€ ì „ì†¡ ì™„ë£Œ
        send_progress.send(100)

        # ê¸°ë³¸ ê²°ê³¼ê°’ (ì •í™•ë„ 90ì´ìƒ ì‹œ)
        result = {
            "basename": base_name,
            "bit_accuracy": bit_acc_pct,
            "detected_at": timestamp,
            'taskId': task_id
        }

        # ì •í™•ë„ < 90ì´ë©´ ì‚½ì… ì´ë¯¸ì§€ í¬í•¨
        if result['bit_accuracy'] < 90:
            result['image_base64'] = pil_to_base64(image)        # ì‚½ì… ì´ë¯¸ì§€

        return jsonify(result)

    except Exception as e:
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=True)